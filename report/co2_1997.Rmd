---
title: "Global $CO_{2}$ Emissions in 1997"
short: "What Keeling missed all these years"
author: "Meral Basit, Alex Hubbard, Mohamed Bakr"
output:
  bookdown::pdf_document2:
    toc: true
    # citation_package: natbib
    fig_caption: true
    latex_engine: pdflatex
fontsize: 11pt
geometry: margin=1in
editor_options: 
  chunk_output_type: inline
bibliography: BibFile.bib
csl: data-science-journal.csl
---

```{r setup, echo=FALSE}
## default to not show code, unless we ask for it.
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE, echo = FALSE, include = FALSE, message = FALSE, warning = FALSE, dpi=1000)
options(digits = 3)
```

```{r load packages, echo = FALSE, message = FALSE}
library(tidyverse)
library(stargazer)
library(tsibble)
library(ggtext)
library(latex2exp)
if (!requireNamespace("forecast", quietly = TRUE)) {
  install.packages("forecast")
}
library(forecast)
library(patchwork)
library(fable)
library(lubridate)
library(fable )
library(feasts)
library(astsa)
library(patchwork)
library(car)

theme_set(theme_minimal())
```

```{r TWS theme, echo = FALSE}
# color palette
BERKELEY_BLUE = "#003262"
CALIFORNIA_GOLD = "#FDB515"
FOUNDERS_ROCK = "#3B7EA1"
MEDALIST = "#C4820E"

custom_palette <- c(
"WHITE" = "#FFFFFF",
"BERKELEY_BLUE" = BERKELEY_BLUE,
"CALIFORNIA_GOLD" = CALIFORNIA_GOLD,
"BLACK" = "#000000",
"FOUNDERS_ROCK" = FOUNDERS_ROCK,
"MEDALIST" = MEDALIST
)

## Create bar chart theme (Adapting Storytelling with Data guidance)
theme_swd_bar <- theme(
  plot.title = element_markdown(size = rel(1.5), color = "#000000"),
  plot.subtitle = element_markdown(),
  text = element_text(color = "#979797"),
  axis.title.x = element_text(hjust = 0, vjust = -0.5),
  axis.title.y = element_text(hjust = 1),
  line = element_blank(),
  rect = element_blank(),
  legend.position = "none",
  legend.justification='left'
)

# Properly format the commas while also removing the decimal places.
scaleFUN <- function(x) format(round(as.numeric(x), 0), nsmall=0, big.mark=",")
```

\newpage

# Background

## Carbon Emissions

Carbon emissions refer to the release of carbon, particularly carbon dioxide ($CO_2$), into the atmosphere. This process primarily occurs through the burning of fossil fuels such as coal, oil, and natural gas, as well as through deforestation and various industrial processes. $CO_2$ is a greenhouse gas, meaning it traps heat in the Earth's atmosphere and contributes to the greenhouse effect, which leads to global warming and climate change.

In our report we are trying to understand the trend of the atmospheric CO2 by asking the following research question:

```{=tex}
\begin{quote}
  \textit{Is there a significant upward trend in atmospheric CO2 levels over time?}
\end{quote}
```
### Null Hypothesis

There is no significant upward trend in atmospheric CO2 levels over time. $H_0: \beta_1 \leq 0$ Where: $\beta_1$ is the trend coefficient over time in a linear regression model of the form $CO2_t = \beta_0 + \beta_1 \cdot t + \epsilon_t$. $CO2_t$ is the atmospheric $CO_2$ level at time $t$.

# Measurement and Data

<!-- (3 points) Task 1a: CO2 data -->

<!-- Conduct a comprehensive Exploratory Data Analysis on the co2 series. This should include (without being limited to) a description of how, where and why the data is generated, a thorough investigation of the trend, seasonal and irregular elements. Trends both in levels and growth rates should be discussed (consider expressing longer-run growth rates as annualized averages). -->

<!-- What you report in the deliverable should not be your own process of discovery, but rather a guided discussion that you have constructed so that your audience can come to an understanding as succinctly and successfully as possible. This means that figures should be thoughtfully constructed and what you learn from them should be discussed in text; to the extent that there is any raw output from your analysis, you should intend for people to read and interpret it, and you should write your own interpretation as well. -->

## Measuring Atmospheric Carbon

In this study, we will use the Mauna Loa Atmospheric $CO_2$ Concentration time series dataset that is a available in `R`. The time series of 468 observations of the monthly Atmospheric concentrations of $CO_2$ from 1959 to 1997 expressed in parts per million (ppm). This means that, for example, a value of 320 means there are 320 CO2 molecules for every 1 million air particles (after the water vapor is removed from the sample). The data was reported in the preliminary 1997 SIO [@keeling1997].

The data was collected at the Mouna Loa Observatory which is located on the island of Hawaii at an elevation of 11,135 feet above sea level which makes this location "well situated to measure air masses that are representative of very large areas" [@gml], [@co2_measurements]. The values for February, March and April of 1964 were missing and have been obtained by interpolating linearly between the values for January and May of 1964.

## Historical Trends in Atmospheric Carbon

The Keeling Curve is a graph of the accumulation of carbon dioxide in the Earth's atmosphere based on continuous measurements taken at the Mauna Loa Observatory on the island of Hawaii from 1958 to the present day. The curve is named for the scientist Charles David Keeling, who started the monitoring program and supervised it until his death in 2005 [@noauthor_keeling_2024]

```{r EDA standard plots}
# turn into tsibble
co2.ts <- as_tsibble(co2)

# time series
p1 <- ggplot(co2.ts, aes(x = index, y = value)) +
  geom_line(linewidth = .5) +
  labs(title = "Atmospheric CO2 1959-1997", x = "Month and Year", y = "CO2 (ppm)") +
  theme_swd_bar

# acf
p2 <- ggAcf(co2.ts$value) + ggtitle("ACF CO2") + theme_swd_bar

# pacf
p3 <- ggPacf(co2.ts$value) + ggtitle("PACF CO2") + theme_swd_bar

# histogram
p4 <- ggplot(co2.ts, aes(x = value)) +
  geom_histogram(bins = 20, fill = "lightblue", color = "black") +
  labs(title = "Histogram of Atmospheric CO2", x = "CO2 (ppm)", y = "Frequency") + 
  theme_swd_bar

# annual average
p5 <- as_tibble(co2.ts) %>%
  mutate(year = year(index)) %>%
  group_by(year) %>%
  summarise(avg_value = mean(value, na.rm=TRUE)) %>%
  ggplot(aes(x=year, y=avg_value)) +
  geom_point() +
  labs(title = "Average Yearly CO2 Levels", x = "Year", y = "Average CO2 (ppm)") + 
  theme_swd_bar

# make layout
pw <- (p1 + p4) /
  (p2 + p3) /
  p5
```

```{r EDA-plots, include=TRUE,fig.cap="Atmospheric CO2 EDA standard plots", fig.width=9, fig.height=5}
pw + plot_annotation(
  title = 'Atmospheric CO2 EDA plots',
  subtitle = 'Upward trend with clear seasonal pattern',
  caption = 'Source: Mauna Loa Atmospheric CO2 Concentration'
)
```

As we see in Figure \@ref(fig:EDA-plots) the time series in the top left, there is a pretty strong seasonality as well as a linear upward trend. Additionally, The dataset is not mean stationary but it may be variance stationary.

The `ACF` decays slowly but does not dampen below the significance level even after lag 24. This suggests a strong autocorrelation in the $CO_2$ values while the `PACF` drops shortly after lag 1 but still has an oscillating pattern with a few lags above the significance level. This suggests that this series may have a unit root. Both `ACF` and `PACF` show seasonality patterns.

The histogram in Figure \@ref(fig:EDA-plots) top right shows that there is a wide range of values with a slight right skew. The yearly average plot on the bottom illustrates the linear trend in the data series more explicitly.

```{r EDA seasonality}
p6 <- co2.ts %>%
  ggplot(aes(x = index, y = value)) +
  geom_line(linewidth = .5) +
  labs(title = "Atmospheric CO2", x = "", y = "CO2 (ppm)") +
  theme_swd_bar

p7 <- ggplot(subset(co2.ts), 
       aes(x = index, y = difference(value,6))) +
  geom_line(linewidth = .5) +
  labs(title = "Seasonally Differenced, Lag 6", x = "Date", y = "CO2 (ppm)") +
  theme_swd_bar
```

```{r def-plot, include=FALSE, fig.cap="Seasonally Differenced CO2 Concentrations (Lag 6)", fig.width=9, fig.height=2}
p7
```

```{r stationarity test KPSS, eval=FALSE, include=FALSE}
co2.ts %>% 
  mutate(log_value = log(value)) %>%
  features(log_value, unitroot_kpss)

co2.ts %>% 
  mutate(diff_value = difference(value, 6)) %>%
  features(diff_value, unitroot_kpss)
```

<!-- Based on the Figure @ref(fig:EDA-plots) and after examining the time series more closely, we noted that the seasonal cycle seemed to be 6 lags long, we applied a seasonal differencing of 6 lags. This transformation resulted in a stationary series. -->

<!-- To confirm this we performed KPSS unit root test. With p-value of 0.1, fail to reject null hypothesis of stationarity, indicating that the transformed series is now stationary Figure @ref(fig:def-plot). -->

# Models and Forecasts

In this section, we will analyze and compare two different models to gain a better understanding of the complex dynamics of the time series process. We will assess a linear model and an ARIMA model to identify the most appropriate time series model for our analysis.

## Linear vs Quadratic Models

<!-- (3 points) Task 2a: Linear time trend model -->

<!-- Fit a linear time trend model to the co2 series, and examine the characteristics of the residuals. Compare this to a quadratic time trend model. Discuss whether a logarithmic transformation of the data would be appropriate. Fit a polynomial time trend model that incorporates seasonal dummy variables, and use this model to generate forecasts to the year 2020. -->

We started by fitting a linear model of the form: $CO2_t=\beta_0+\beta_1t+\epsilon_t$. Based on the fit results, the estimated coefficient $\beta_1 = 0.109$ indicates that the $CO_2$ levels increase by $\approx 0.109$ units per month. The p-value of the time index is $<0.05$ which suggests that the coefficient is statistically significant. We reject the null hypothesis that the coefficient $\beta_1 = 0$. That also provides evidence that the $CO_2$ levels have an upward linear trend.

Both $R^2$ and the adjusted $R^2$ value is $0.969$, which means that the linear model can explain $96.9$% of the $CO_2$ levels variance, suggesting that the model effectively captures the main patterns in the data.

```{r linear model}
mod.linear <- lm(value ~ time(index), data = co2.ts)
summary(mod.linear)

# Plot the linear model
lm.mod.plot <- co2.ts |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() +
  geom_line(aes(y = predict(mod.linear)), color = BERKELEY_BLUE) +
  labs(title = "CO2 Levels with Fitted Linear Time Trend Model", x = "Month", y = "CO2 (ppm)") +
  theme_swd_bar

# Plot the residuals
lm.mod.res <- co2.ts |> 
ggplot( aes(x = index, y = resid(mod.linear))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(formula = 'y ~ x',method = "loess", color = "blue", se = FALSE) +
  labs(title = "Linear Time Trend Model Residuals", x = "Month", y = "Residuals") +
  theme_swd_bar

# residualPlot(mod.linear, main="Linear Residuals")
confint(mod.linear)
```

Next, we fit a quadratic model of the form: $CO2_t= \beta_0 + \beta_1 t + \beta_2 t^2 + \epsilon_t$. Based on the fit results of the quadratic time trend model, the estimated coefficient $\beta_1 = 0.0674$ indicates that the $CO_2$ levels increase by $\approx0.0674$ units per month. The p-value of the time index is $<0.05$ which suggests that the coefficient is statistically significant. We reject the null hypothesis that the coefficient $\beta_1 = 0$. that also provides evidence that the $CO_2$ levels have an upward linear trend.

The estimated quadratic term coefficient $\beta_2 = 0.0000886$. The positive coefficient suggests that the rate of increase in CO2 levels is accelerating. The p-value of the time index is $<0.05$ which suggests that the coefficient is statistically significant. We reject the null hypothesis that the coefficient $\beta_2 = 0$.

Both $R^2$ and the adjusted $R^2$ value is $0.979$, which means that the linear model can explain $97.9$% of the $CO_2$ levels variance, suggesting that the model effectively captures the main patterns in the data.

After analyzing the two models, it is obvious that the significant coefficients show a clear upward trend in CO2 levels over time, with a rapidly increasing rate. However, it seems that the quadratic model is slightly outperforming the linear model when comparing the $R^2$ results and examining the residual plots in Figure \@ref(fig:res-compare).

```{r quadratic model}
mod.quadratic <- lm(value ~ time(index) + I(time(index)^2), data = co2.ts)
summary(mod.quadratic)

# Plot the quadratic model
quad.mod.plot <- co2.ts |>
ggplot(aes(x = index, y = value)) +
  geom_line() +
  geom_line(aes(y = predict(mod.quadratic)), color = CALIFORNIA_GOLD) +
  labs(title = paste("Fitted <strong><span style='color:" , CALIFORNIA_GOLD ,"'>Quadratic</span></strong> Time Trend Model"), x = "Month", y = "CO2 (ppm)") +
  theme_swd_bar

# Plot quadratic model residuals
quad.mod.res <- co2.ts |>
ggplot(aes(x = index, y = resid(mod.quadratic))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(formula = 'y ~ x', method = "loess", color = "blue", se = FALSE) +
  labs(title = "Quadratic Time Trend Model Residuals", x = "Month", y = "Residuals") +
  theme_swd_bar

# residualPlot(mod.quadratic, main="Quadratic residuals")
confint(mod.quadratic)
```

```{r res-compare, include=TRUE,fig.cap="Residuals of the Linear and Quadratic Models", fig.width=9, fig.height=3}
(lm.mod.res + quad.mod.res)
```

```{r log-linear}
# Log transformation for linear model
log.mod.linear <- lm(log(value) ~ time(index), data = co2.ts)
summary(log.mod.linear)

# Plot the log linear model
log.lm.mod.plot <- co2.ts |> 
  ggplot(aes(x = index, y = log(value))) +
  geom_line() +
  geom_line(aes(y = predict(log.mod.linear)), color = FOUNDERS_ROCK) +
  labs(title = "CO2 Levels with Fitted Linear Time Trend Model", x = "Month", y = "CO2 (ppm)") +
  theme_swd_bar

log.lm.mod.res <- co2.ts |> 
ggplot( aes(x = index, y = resid(log.mod.linear))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(formula = 'y ~ x',method = "loess", color = "blue", se = FALSE) +
  labs(title = "Log-Linear Time Trend Model Residuals", x = "Month", y = "Residuals") +
  theme_swd_bar
```

A logarithmic transformation can stabilize variance and make growth trends more linear. However, in this case, the log-linear model with $R^2 = 0.972$ does not significantly improve the fit compared to the quadratic model with $R^2 = 0.979$.

## Polynomial Model

```{r polynomial model}
# Add seasonal dummy variables
co2.ts <- co2.ts |> 
  mutate(month = factor(month(index)))

# Fit the polynomial model with seasonal dummies
mod.poly.season <- lm(value ~ time(index) + I(time(index)^2) + month, data = co2.ts)
summary(mod.poly.season)

# Plot the polynomial model
poly.mod.plot <- co2.ts |>
ggplot(aes(x = index, y = value)) +
  geom_line() +
  geom_line(aes(y = predict(mod.poly.season)), color = FOUNDERS_ROCK) +
  labs(title = paste("Fitted <strong><span style='color:" , FOUNDERS_ROCK ,"'>Polynomial</span></strong> Time Trend Model"), x = "Month", y = "CO2 (ppm)") +
  theme_swd_bar

# Plot quadratic model residuals
poly.mod.res <- co2.ts |>
ggplot(aes(x = index, y = resid(mod.poly.season))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(formula = 'y ~ x', method = "loess", color = "blue", se = FALSE) +
  labs(title = "Polynomial Time Trend Model Residuals", x = "Month", y = "Residuals") +
  theme_swd_bar

# residualPlot(mod.poly.season, main="Polynomial model residuals")

# Poly Model Accuracy 
rmse.poly.season <- summary(mod.poly.season)$sigma
```

As you can see in Figure \@ref(fig:quad-vs-poly), adding a seasonal dummy variable to a polynomial model helps to capture some of the seasonal variation that we see in the historical $CO_2$ levels and improves the model's fit with $R^2 = 0.998$.

```{r quad-vs-poly, include=TRUE, fig.cap="Quadratic Model vs Polynomial with seasonal dummies", fig.width=9, fig.height=4}
quad.mod.plot + poly.mod.plot
```

## ARIMA Models

<!-- Following all appropriate steps, choose an ARIMA model to fit to the series. Discuss the characteristics of your model and how you selected between alternative ARIMA specifications. Use your model (or models) to generate forecasts to the year 2022. -->

Based on the EDA and `ACF` and `PACF` plots in Figure \@ref(fig:EDA-plots), it was challenging to determine the parameters $p$ and $q$ using a combination. Therefore, we used `AIC` and `BIC` to estimate the parameters.

```{r test train split}
co2_train <- co2.ts %>% 
  filter(index < ymd(19950101))

co2_test <- co2.ts %>% 
  filter(index >= ymd(19950101))
```

To estimate the $i$ parameter, we used the `KPSS` test to check for stationarity. Initially, the p-value was 0.01, leading us to reject the null hypothesis, indicating non-stationarity. After differencing once, the p-value went up to 0.1, and we failed to reject the null hypothesis, indicating that the data is stationary after one differencing.

```{r stationarity test}
co2_train %>% 
  features(value, unitroot_kpss)

co2_train %>% 
  mutate(diff = difference(value)) %>% 
  features(diff, unitroot_kpss)

co2_train %>% features(value, unitroot_ndiffs)

co2_train %>% 
  gg_tsdisplay(difference(value), plot_type = "partial") +
  labs(subtitle = "CO2")
```

We split the data into training and test datasets. We will use 1995 through 1997 as our test data, and pre-1995 as our training data. We then estimated an ARIMA(2,1,0)(2,1,0)[12] model as a baseline plus four additional models, using both the regular and the logarithmic transformed $CO_2$ value once using stepwise and and non-stepwise search.

```{r ARIMA model fit}
co2_fit <- co2_train %>% 
  model(
    baseline = ARIMA(value ~ 0 + pdq(2,1,0) + PDQ(2,1,0)),
    arima_fit = ARIMA(value),
    arima_fit.search = ARIMA(value, stepwise = FALSE),
    arima_fit_log = ARIMA(log(value)),
    arima_fit_log.search = ARIMA(log(value), stepwise = FALSE)
  )

# Estimated models results
co2_fit |> pivot_longer(cols = everything(), names_to = "Model name",
                         values_to = "Orders") |> 
  knitr::kable(caption = "Estimated ARIMA Models")
```

```{r ARIMA-results, include=TRUE, fig.cap="ARIMA Models Comparison", fig.height=2}
# Model Comparison
glance(co2_fit) |>
  arrange(AICc) |> 
  select(.model:BIC) |> 
  mutate_if(is.numeric, round, digits =2) |> 
  knitr::kable(caption = "ARIMA Models Comparison")
```

By examining Table \@ref(tab:ARIMA-results), we find that the model with the lowest AICc value is ARIMA(3,1,0)(2,1,0)[12] with a log transformation. This aligns with our earlier observation that the log transformation yields better results.

```{r model coefs}
# Inflation rates Model coefs
co2_fit|>
  select(arima_fit_log.search) |>
  report()
```

The residuals line and `ACF` plots Figure \@ref(fig:ARIMA-residual) from the ARIMA(3,1,0)(2,1,0)[12] model show that all autocorrelations are within the threshold limits, indicating that the residuals are behaving like white noise which is confirmed by `Ljung Box` test with a p-value = 0.358 we fail to reject the null hypothesis $H_0: \text{data is independently distributed}$.

```{r ARIMA-residual, include=TRUE, fig.cap="ARIMA(3,1,0)(2,1,0)[12] Model Residuals", fig.width=9, fig.height=3}
co2_fit |> 
  select(arima_fit_log.search) |> 
  gg_tsresiduals()
```

```{r ARIMA ljung-box}
augment(co2_fit) |> 
  filter(.model == "arima_fit_log.search") |>  
  features(.innov, ljung_box, lag = 10, dof = 0)
```

## Forecasts

```{r forecast}
# Generate the prediction time series to 2020
start_date <- as.Date("1998-01-01")
end_date <- as.Date("2020-12-31")

dates <- seq(from = start_date, to = end_date, by = "month")

yearmonth_2020 <- data.frame(index = yearmonth(dates)) |> 
  mutate(month = factor(month(index), levels = levels(co2.ts$month))) |> 
  as_tsibble()

# Combine the original data with the future dates
extended.ts <- bind_rows(co2.ts, yearmonth_2020)

# Generate forecasts
forecasts <- predict(mod.poly.season, newdata = extended.ts)

# Combine the actual and forecasted data
combined.data <- extended.ts |>  mutate(predictions = forecasts)

# Avg 2020 forecasted CO2 levels
predict.2020 <- combined.data |> 
  filter(index >= yearmonth("2020 Jan") & index <= yearmonth("2020 Dec"))

avg.co2.2020 <- mean(predict.2020$predictions, na.rm = TRUE)
  
# Plot the forecasts
prediction_plot <- ggplot(combined.data, aes(x = index)) +
  geom_line(aes(y = value), color = "black", linewidth = 1) +
  geom_line(aes(y = predictions), color = "cornflowerblue", linetype = "dashed") +
  geom_vline(xintercept = as.Date("1997-12-01"), linetype = "dashed", color = "red") +
  annotate("text", x = as.Date("1997-12-01"), y = 390, label = "Forecast Start", angle = 90, vjust = -0.5) +
  labs(title = "CO2 Levels with Polynomial Seasonal Model Predictions",
       x = "Month", y = "CO2 (ppm)") + 
  theme_swd_bar
```

```{r poly-plot, include=FALSE, fig.cap="Predicted Atmospheric CO2 levels till 2020", fig.width=9, fig.height= 3}
prediction_plot
```

```{r ARIMA Forecast}
# Forecasting till the year 2100 (2100 - 1995 = )
forecasts <- co2_fit |> 
  select(arima_fit_log.search) |>
  forecast(h="106 years")

forecasts.int <- forecasts |> 
  hilo(level=c(80, 95))

forecasts |> 
  autoplot(colour="cornflowerblue") + 
  autolayer(co2.ts, colour="black") + 
  geom_line(data=co2_fit |> 
              augment() |>
              filter(.model %in% c("arima_fit_log.search")),
            aes(index,.fitted,color=.model)) +
  labs(y = "Avg CO2 (ppm)",title = "Average CO2 ppm") + guides(colour = guide_legend(title = "Forecast"))+
  facet_wrap(~.model, ncol=1, nrow=2)

# ARIMA model Accuracy
rmse.arima <- accuracy(forecasts, co2.ts)['RMSE']

# Find the first time CO2 levels reach 420 ppm
time_420 <- forecasts.int |> filter(.mean >= 420) |> slice(1)
date_420 <- time_420$index
cof.int.420 <- time_420$`95%`

# Find the first time CO2 levels reach 500 ppm
time_500 <- forecasts.int |> filter(.mean >= 500) |> slice(1)
date_500 <- time_500$index
cof.int.500 <- time_500$`95%`

# Predict CO2 levels in the year 2100
forecast_2100 <- forecasts.int |> 
  filter(year(index) == 2100)

conf.int.2100.lower <- forecast_2100$`95%`[1]
conf.int.2100.upper <- forecast_2100$`95%` |> tail(1)

avg.co2.2100 <- round(mean(forecast_2100$.mean),0)

```

Using the polynomial model with seasonal dummies, we predict that CO2 levels will reach `r round(avg.co2.2020,2)` ppm on average by 2020.

Using our best model the ARIMA(3,1,0)(2,1,0)[12], we predicted that the $CO_2$ levels will reach 420 ppm by `r date_420` with `r round(cof.int.420,0)`% confidence interval while it predicts it will reach 500 ppm by `r date_500` with `r round(cof.int.500,0)`% confidence interval.

By 2100, our model predicts that CO2 levels will be at about `r avg.co2.2100` ppm on average with confidence intervals varying between `r round(conf.int.2100.lower,0)`% and `r round(conf.int.2100.upper,0)`%. These predictions are may be highly inaccurate, since we are forecasting too far into the further. Additionally, our model does not account for any unforeseen events that might impact the rate of increase. For example, increases in efficiency and decarbonization of the grid may decrease the slope of the graph. The prediction intervals provide a measure of this uncertainty: the further the projected point, the wider the intervals.

# Conclusions

The polynomial model fits the $CO_2$ time series data well, explaining nearly 99.8% of the variance in $CO_2$ levels. The significant coefficients indicate a strong upward trend in atmospheric $CO_2$ levels over time with an accelerating rate of increase. We reject the null hypothesis $H_0: \beta_1 \leq 0$. This model provides a more nuanced understanding of the trend and variability in $CO_2$ levels compared to the simpler linear models estimated here.

The selected ARIMA model (e.g., ARIMA(3, 1, 0)(2, 1, 0)[12]) effectively captures the trend and seasonality in the $CO_2$ time series data. The model diagnostics indicate a good fit, and the model suggests significant increases in atmospheric $CO_2$ levels if current trends continue. However, while the point estimates provide specific values, the prediction intervals highlight the uncertainty in the long-term forecasts.

Finally, ARIMA model with RMSE `r round(rmse.arima, 2)` performed better than the Polynomial model with RMSE `r round(rmse.poly.season, 2)`.

\newpage

```{=tex}
\appendix
\section{Appendix: Model comparison}
```
```{r}
# Create a list of models
models <- list(mod.linear, log.mod.linear, mod.quadratic, mod.poly.season)

# Add appropriate model names
names(models) <- c("Linear Model", "Log Linear Model", "Quadratic Model", "Polynomial Model")
```

```{r stargazer-table, warning=FALSE, include=TRUE, results='asis', tab.cap="Estimated Time Series Models"}
# Generate the stargazer table
stargazer(models, 
          type = "latex",
          omit.stat = "f",
          single.row = TRUE,
          title = "Estimated Time Series Models",
          label = "tab:stargazer-table",
          column.labels = names(models),
          dep.var.caption  = "Output Variable: expected Atmospheric $CO_2$ Levels ",
          dep.var.labels   = "",
          header = F,
          digits = 2
          # add.lines = list(
          #   c("AIC", prettyNum(round(criteria_df$AIC, 2), big.mark = ",")),
          #   c("AICc", prettyNum(round(criteria_df$AICc, 2), big.mark = ",")),
          #   c("BIC", prettyNum(round(criteria_df$BIC, 2), big.mark = ","))
          #)
)
```

# Refrences

```{=tex}
\bibliographystyle{aea}
\bibliography{BibFile}
```
